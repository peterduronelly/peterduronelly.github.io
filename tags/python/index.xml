<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Tiny Little Things in Data Science</title>
    <link>https://peterduronelly.github.io/tags/python/</link>
    <description>Recent content in Python on Tiny Little Things in Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 14 May 2019 20:19:21 +0200</lastBuildDate>
    
	<atom:link href="https://peterduronelly.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Detect Csv Delimiters</title>
      <link>https://peterduronelly.github.io/post/detect-csv-delimiters/</link>
      <pubDate>Tue, 14 May 2019 20:19:21 +0200</pubDate>
      
      <guid>https://peterduronelly.github.io/post/detect-csv-delimiters/</guid>
      <description>One of the most frequent format for data import and export in python is CSV. Reading and loading a CSV file to pandas is straightforward – assuming you know the separator, or the separator is a comma. While the name Comma Separated Values implies CSV file automatically use comma as separator (also called delimiter) this is not always the case. Depending on your settings the separator can be anything from semicolons to pipe character.</description>
    </item>
    
    <item>
      <title>Train Test Splitting Time Series Data</title>
      <link>https://peterduronelly.github.io/post/train-test-splitting-time-series-data/</link>
      <pubDate>Tue, 20 Nov 2018 15:45:04 +0100</pubDate>
      
      <guid>https://peterduronelly.github.io/post/train-test-splitting-time-series-data/</guid>
      <description>Machine learning is not the ideal tool for time series forecasting for a number of reasons, but, as I will demonstrate it in a future post, limited models can be built for short-term forecasting exercises. One aspect of time series data is, however, that you can’t split your observations randomly into train and test subsets: you train on an early interval and test on a later one. Standard ML libraries, such as scikit-learn, don’t provide a tool for that.</description>
    </item>
    
    <item>
      <title>Clustering on a Dissimilarity Matrix</title>
      <link>https://peterduronelly.github.io/post/clustering-on-dissimilarity-matrix/</link>
      <pubDate>Fri, 14 Sep 2018 10:33:36 +0200</pubDate>
      
      <guid>https://peterduronelly.github.io/post/clustering-on-dissimilarity-matrix/</guid>
      <description>Clustering is one of the well-known unsupervised learning tools. In the standard case you have an observation matrix where observations are in rows and variables which describe them are in columns. But data can also be structured in a different way, just like the distance matrix on a map. In this case observations are by both rows and columns and each element in the observation matrix is a measure of distance, or dissimilarity, between any two observations.</description>
    </item>
    
    <item>
      <title>Sparse Matrices in Python</title>
      <link>https://peterduronelly.github.io/post/sparse-matrices-in-python/</link>
      <pubDate>Thu, 13 Sep 2018 11:17:13 +0200</pubDate>
      
      <guid>https://peterduronelly.github.io/post/sparse-matrices-in-python/</guid>
      <description>One of the things we need to manage in data analysis is recources. When we have large amounts of (&amp;lsquo;big&amp;rsquo;) data this can become a serious issue. One of the cases when we need to consider whether we really need all the data we have is when we have a lot of zeros in our database, and these zeroes happen to be irrelevant for our calculations. Python&amp;rsquo;s SciPy library has a solution to store and handle sparse data matrices which contain a large number of irrelevant zero values.</description>
    </item>
    
  </channel>
</rss>